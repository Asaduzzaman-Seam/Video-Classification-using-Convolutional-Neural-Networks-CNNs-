# Video-Classification-using-Convolutional-Neural-Networks-CNNs-

## VIDEO CLASSIFICATION USING CONVOLUTIONAL NEURAL NETWORKS by
### Asaduzzaman Seam - 180105100
### Mahtub Alsab Saykat - 180105098
### Abu Muhammad Shafayat Kabir - 180105095
### Anwar Hakim Tamim - 180105092

## Acknowledgements
We are hugely appreciative of our university supervisor, Mr. Nahyan Al  Mahmud, who has been a truly dedicated mentor. Thank you for being our supervisor, sharing your experience, and providing wonderful academic support. You are the one to ask any question whenever we encounter a problem. Thank you once more for your efforts. 
Finally, we must express our deepest gratitude to our parents for their unwavering support and ongoing encouragement during the course of our years of study as well as during the process of doing our research and preparing our thesis. Without them, this  accomplishment would not have been possible.

## Abstract
The quantity of bandwidth available on the internet has grown quickly in recent years. The exchange of information (text, audio, and video), which is so inexpensive thanks to internet connectivity,  is  increasingly  widespread  and  quick.  The  video  content  needs  to  be predicted, evaluated, and categorized for different user needs. In the realm of computer vision, video classification is a significant and actively studied issue. Machine learning models have demonstrated to function remarkably  effectively in order to produce highquality  outputs.  For  the  analysis  of  visual  data,  existing  techniques  primarily  use conventional neural network (CNN) models.  This data is particularly complex because of its large dimensionality. There is a substantial danger of losing important information as a result of the learning algorithms' limitations on how they can handle the data. However, in order for CNNs to analyse the video clips, which are typically variable in duration, they must be translated onto smaller, fixed-dimensional vector representations of the features. Additionally, this adds a cost for preprocessing information before the desired results may be  obtained.  Modified  convolutional  neural  networks  (CNNs  and  RNNs)  have  recently shown to be effective at analyzing sequence-based data without significantly sacrificing information. With an emphasis on the LSTM layer, the aim of this work is to compare the performance of ConvLSTM and LRCN models for video categorization. We create end-toend trainable recurrent convolutional models that are appropriate for quick or extensive visual learning, and we show their utility on benchmark video identification tasks. Both models might theoretically work well for the analysis of visual data because it is highly complex and sequential in nature. With the help of ConvLSTM and LRCN models, we conduct these experiments with the goal of analyzing the outcomes.  Our final goal is to assess the best performing model utilizing prebuilt datasets and random datasets.

## Introduction
Convolutional neural networks can be described as the principal algorithm for image and video classification in the field of computer vision. In the present time, the algorithm of neural networks provides efficient performance to identify and dissect image and per frame image. The images per frame  can be considered  for the video recognition method. The assimilation of semantic incident is quite captivating in the latest technologies of this field. It explains that an order of human  gestures in  a video can be detected as motions. For example, bicycling, diving, kayaking, etc. Since the initiation, Computer vision problem has  been  distributed  into  smaller  problems  in  a  repetitive  manner,  for  example,  image enhancement, object detection, noise removal, segmentation, video processing, and many more  in  order  to  understand  the  semantic  information  for  the  data.  This  sets  close  ties among machine learning, pattern recognition, image processing  and computer graphics. One of the most considerable problems faced in the field of Computer Vision is that of Video  Classification.  The  process  of  Video  Classification  automatically  differentiates between different types of videos based on their semantic data. Due to various applications like video identification and client investigation human action realization is a far-reaching research area. Action recognition is mainly used for detection of specific activities from a video frame and to expatriate those frames therefore. Universal and robust models can be delivered by the Convolution neural networks for image or video recognition systems with negligible manual work and can be extended easily to many applications.

The actual motivation for the advancement of the effective video recognition systems is an overwhelming  phenomenon  in  the  volume  of  media  data  over  internet  networks.  The secondary motivation is the augmented esteem of imaging devices like digital camera and increasing dissemination of image data over communication networks. The emergence of new consumerism where media technologies meet consumer criteria. Extensive research has been performed to classify and identify the videos based on their semantic data which can potentially lead to the development of applications of video classification in various fields  including  health  care,  education,  security  and  surveillance,  legal  services  and entertainment. Machine Learning algorithms have proven to be a good solution to solve the problem  of  Computer  Vision  in  general  and  video  classification  especially.  Neural Networks have provided a nonlinear method of mathematically modelling the data. The layered structure in this set of learning algorithms is the main tool for generating good results. A video recognition system is generally an application where users can compile queries such as, “Show medical history of bone fracture cases with X-ray scans identical to this case”. The target is to solve the basic problems with the application by finding the images  that  are  visually  similar.  Visual  similarity  can  be  figured  out  utilizing  many algorithmic ways, but not all the process is effective. General and classic measures such as Euclidian distance or Manhattan distance only calculates the imparity between pixel values while totally neglecting visual queue. The present algorithm for video recognition is not flawless  and  computationally  correct  and  therefore  to  apply  in  actual  application  takes much  effort.  Since  a  robust  model  is  designed,  implemented  and  applied  in  real  that completes all the real-time constraints and is more useful and accurate when compared to the traditional existing models.

In this research, the possibility of CNNs as potential visual data classification solution has been investigated using Long Short-Term Memory (LSTM) and & Long Term Recurrent Convolutional Network (LRCN). Details about the approach used  have been provided in Chapter 4  of this  report  followed by the Chapter 5  containing  experimental details and achieved results.

As a summary, this report describes the baseline prospects about the probability of CNNs as a solution to the Video  classification problem. The overview for Video Classification research has been provided, applications and effectiveness of CNNs and a review of the work carried out to classify videos through the selected model of CNN. Then, a discussion about  the  system  architecture  followed  by  the  overview  of  experiments  performed  and discussion about the results achieved. This reports also provides a critical reflection about the  research  project  management,  success  and  failures  have  been  discussed  along  with potential issues associated with the research for potential social impact and at professional level  in  Chapter  6.  Some  ideas  about  the  further  steps  which  can  be  taken  in  order  to improve the results have also been discussed.

